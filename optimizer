
class optimizer():
    def __init__(self, s, e, delta, time_delta = None, epsilon = 1e-3, max_iter = 30):
        
        self.s = s
        print(self.s)
        self.e = e
        self.e_true = np.array([
        (self.e["Heading"]) , #% (2 * np.pi)
        self.e["Speed"],
        self.e["Height"],
        self.e["X"],
        self.e["Y"]
        ])
        
        self.m = int(len(delta["heading"]) * 6)
        self.N = int(self.m // 6)
        self.mu = 10 * np.ones(self.m)
        self.epsilon = epsilon
        self.max_iter = max_iter
        self.weight = np.array([3*1e-2, 10, 10, 3, 3]) # heading, speed, height, X, Y
        self.min_turn_R = 25
        
        self.DV = np.vstack([delta["heading"].reshape(-1, 1), delta["Slope"].reshape(-1, 1), delta["speed"].reshape(-1, 1)]).flatten()
        self.org_slope = delta["Slope"].reshape(-1, 1).flatten()
        self.org_heading = delta["heading"].reshape(1, -1).flatten()
        
        if time_delta is None:
            self.time_delta = np.ones(self.N)
        else:
            self.time_delta = time_delta
            
        self.grad_g = self.grad_g(self.N)
        self.tau = self.compute_tau()
        
    def grad_g(self, N):
        I = np.eye(N)
        Z = np.zeros((N, N))
        Z_s = Z[1:, :]
        I_s = np.vstack([np.zeros((1, N)), I[1:, :]])
        L = np.vstack([np.zeros((1, N)), np.tril(np.ones((N, N)))[1:, :]])
        R = self.min_turn_R
        M = np.block([
        [  Z,   I,   Z ],
        [ -Z,   I,   Z ],
        [  I_s,   Z,  -L/R ],
        [  I_s,  -Z,  -L/R ],
        [  Z,   Z,   I_s ],
        [  Z,   Z,  -I_s ]
        ])
        
        return M
        
    def cost_cal(self, DV):
        """
        s 기준 e 예측값과 e 간의 weighted 차이 계산
        """
        dv_heading = DV[:self.N]
        dv_slope = DV[self.N:2*self.N]
        dv_speed = DV[2*self.N:3*self.N]
        
        # 예측된 최종 값 계산
        Heading_cum = (self.s["Heading"] + np.cumsum(dv_heading)) #% (2 * np.pi)
        Speed_cum = self.s["Speed"] + np.cumsum(dv_speed)
        Speed_pred = Speed_cum[-1]
        Height_pred = self.s["Height"] + np.sum(Speed_cum * np.tan(dv_slope))
        
        X_pred = self.s["X"] + np.sum(Speed_cum * np.sin(Heading_cum))
        Y_pred = self.s["Y"] + np.sum(Speed_cum * np.cos(Heading_cum))
        
        e_true = self.e_true
        
        error_heading = np.cos(e_true[0])  - np.cos(Heading_cum[-1]) #% (2*np.pi)
        error_speed   = e_true[1] - Speed_pred
        error_height  = e_true[2] - Height_pred
        error_X  = e_true[3] - X_pred
        error_Y = e_true[4] - Y_pred
        
        
        w_heading, w_speed, w_height, w_x, w_y = self.weight
        
        cost_RH = 0.5 * ((error_heading / w_heading)**2 + (error_X/w_x)**2 + (error_Y/w_y)**2 ) #
        cost_SH = 0.5 * ((error_height / w_height)**2 + (error_speed /w_speed)**2 ) # 
        
        error_RH_norm = np.sqrt(error_heading**2 + (error_X)**2 + (error_Y)**2)
        
        delta_thresh = 10
        gamma = 3
        
        if error_RH_norm > delta_thresh:
            adaptive_factor = 1.0 + gamma * (error_RH_norm - delta_thresh)
        else:
            adaptive_factor = 1.0
            
        lambda_slope = 1.0
        cost_slope = 0.5 * lambda_slope * np.sum((dv_slope - self.org_slope.flatten())**2) / self.N

        total_cost =  adaptive_factor * cost_RH + cost_SH #+ cost_slope 
    
        
        return total_cost
    
    def constraint_cal(self, DV, R = 50, slope_ths = 0.1, acc_ths = 3):
        """
        제약조건 식 계산하기, 6N x 1
        """
        heading = DV[0:self.N]
        Slope = DV[self.N : 2 * self.N]
        speed = DV[2*self.N : 3 * self.N]
        Speed = self.s["Speed"] + np.cumsum(speed)
        
        # 위에서 10m로 지정
        R = self.min_turn_R
        
        Slope_cst = np.vstack([
            (Slope - slope_ths * np.ones(self.N) ).flatten(),
            (-Slope - slope_ths * np.ones(self.N) ).flatten()
        ])
        
        heading_cst = np.vstack([
            np.insert((np.dot((heading - self.org_heading), self.time_delta) - Speed/R)[1:], 0, 0).flatten(),
            np.insert((np.dot((-heading + self.org_heading), self.time_delta) - Speed/R)[1:], 0, 0).flatten()
        ])
        
        speed_cst = np.vstack([
            (np.insert(speed[1:] - acc_ths, 0, 0)).flatten(),
            (np.insert(-speed[1:] - acc_ths, 0, 0)).flatten()
        ])
        
        return np.vstack([
          Slope_cst, heading_cst, speed_cst
        ]).flatten()
    
    def hessian_cal(self, DV = None, epsilon=1e-6):
        if DV is None:
            DV = self.DV
        
        x = np.asarray(DV, dtype=float)
        n = x.size
        hessian = np.zeros((n, n))
        
        # f(x) 값 (필요시 사용)
        fx = self.cost_cal(x)
        
        # 대각 성분 계산 (이중 중앙 차분)
        for i in range(n):
            x_forward = np.copy(x)
            x_backward = np.copy(x)
            x_forward[i] += epsilon
            x_backward[i] -= epsilon
            f_forward = self.cost_cal(x_forward)
            f_backward = self.cost_cal(x_backward)
            hessian[i, i] = (f_forward - 2 * fx + f_backward) / (epsilon ** 2)
        
        # 비대각 성분 계산 (혼합 편미분: 중앙 차분)
        for i in range(n):
            for j in range(i+1, n):
                x_pp = np.copy(x)
                x_pm = np.copy(x)
                x_mp = np.copy(x)
                x_mm = np.copy(x)
                # 두 변수에 대해 epsilon 만큼 변화
                x_pp[i] += epsilon; x_pp[j] += epsilon  # f(x_i+eps, x_j+eps)
                x_pm[i] += epsilon; x_pm[j] -= epsilon  # f(x_i+eps, x_j-eps)
                x_mp[i] -= epsilon; x_mp[j] += epsilon  # f(x_i-eps, x_j+eps)
                x_mm[i] -= epsilon; x_mm[j] -= epsilon  # f(x_i-eps, x_j-eps)
                
                f_pp = self.cost_cal(x_pp)
                f_pm = self.cost_cal(x_pm)
                f_mp = self.cost_cal(x_mp)
                f_mm = self.cost_cal(x_mm)
                
                # 중앙 차분 공식 (혼합 편미분)
                hess_ij = (f_pp - f_pm - f_mp + f_mm) / (4 * epsilon**2)
                hessian[i, j] = hess_ij
                hessian[j, i] = hess_ij  # Hessian은 대칭 행렬
        
        return hessian
    
    def jacobian_cal(self, DV = None, epsilon=1e-6):
        if DV is None:
            DV = self.DV
            
        x = np.asarray(DV, dtype=float)
        n = x.size
        jacobian = np.zeros((1, n))
        
        for i in range(n):
            x_forward = np.copy(x)
            x_backward = np.copy(x)
            x_forward[i] += epsilon
            x_backward[i] -= epsilon
            f_forward = self.cost_cal(x_forward)
            f_backward = self.cost_cal(x_backward)
            jacobian[0, i] = (f_forward - f_backward) / (2 * epsilon)
        
        return jacobian
    
    def compute_tau(self, DV = None):
        if DV is None:
            DV = self.DV
        
        g = self.constraint_cal(DV)
        tau =  - (np.dot(self.mu, g)) / self.m
        return tau
    
    def compute_residuals(self, DV = None):
        """
        primal residual, central residual 계산
        """
        if DV is None:
            DV = self.DV
            
        jacobian = self.jacobian_cal(DV)
        hessian = self.hessian_cal(DV)
        g = self.constraint_cal(DV)
        
        dual_residual = (jacobian + self.grad_g.T @ self.mu).reshape(-1, 1)
        central_residual = (g  + self.tau * np.ones(self.N * 6)).reshape(-1, 1)
        
        residuals_ = np.vstack([dual_residual, central_residual]).flatten()
        
        return residuals_, jacobian, hessian, g
    
    def compute_step(self, residuals, hessian, g):
        """
        newton step 계산, delta x, u 벡터 계산산
        """
        #residuals = self.compute_residuals()
        
        grad_residual = np.vstack([np.hstack([hessian, self.grad_g.T]),
                                   np.hstack([np.diag(self.mu) @ self.grad_g, np.diag(g)])])
        
        try:
            delta_x =  -grad_residual @ residuals #np.linalg.inv(grad_residual) 
        except Exception as e:
            print("singular matrix")
            delta_x = np.linalg.pinv(grad_residual + 10e-6 * np.eye(self.N * 9)) @ -residuals
        
        return delta_x
        
    
    def backtracking_line_search(self, delta_x, residuals, alpha = 0.2, beta = 0.99):
        delta_DV = delta_x[:self.N * 3]
        delta_mu = delta_x[self.N * 3:self.N * 9]
        
        idx = np.where(delta_mu < 0)[0]
        if idx.size > 0:
            theta_candidate = np.min(-self.mu[idx] / delta_mu[idx])
            theta_ = min(1, theta_candidate)
        else:
            theta_ = 1.0
        
        constraint_match = False
        
        while not constraint_match:
            if np.all(self.constraint_cal(self.DV + theta_ * delta_DV) <= 0) :
                constraint_match = True
            else : 
                theta_ *= beta
        #print("const match done")
        
        residuals_match = False
        org_cost = self.cost_cal(self.DV)
        
        while not residuals_match:
            new_DV = self.DV + theta_ * delta_DV
            new_cost = self.cost_cal(new_DV)    
            # residuals_update, jacobian, hessian, g = self.compute_residuals()
            
            
            if new_cost <= (1 - alpha * theta_) * org_cost :  #np.linalg.norm(residuals)
                residuals_match = True
            else:
                theta_ *= beta
        #print("res match done")
        print(theta_)
        return theta_ #* (0.9 ** 10)
    
    def optimize(self):
        iter_ = 0
        
        while iter_ <= self.max_iter: #
            
            residuals_, jacobian, hessian, g = self.compute_residuals(self.DV)
            dual_norm = np.linalg.norm(residuals_[:self.N * 3])
            central_norm = np.linalg.norm(residuals_[self.N * 3:self.N * 9])
            cost_ = self.cost_cal(self.DV)
            
            print(f"iter {iter_}) dual res: {dual_norm}, central res: {central_norm}, cost: {cost_}")
            
            if  (dual_norm< 990) and (central_norm< 300) and (cost_ < 0.5):
                print(f"iter {iter_}: residual dual {dual_norm} central {central_norm}")
                print("residual lower than ths, end optimization")
                break
            
            delta_x = self.compute_step(residuals_, hessian, g)
            theta_ = self.backtracking_line_search(delta_x, residuals_)
            
            self.DV = self.DV + theta_ * delta_x[:self.N * 3]
            self.mu = self.mu + theta_ * delta_x[self.N * 3:self.N * 9]
            self.tau = self.compute_tau()
            
            
            iter_ += 1
            
        return self.DV
    
    
def opt_result(s, e, optimizer_, ref_GPS = None, show = True):

    new_DV = optimizer_.DV
    heading = new_DV[:optimizer_.N]
    Slope = new_DV[1 * optimizer_.N:2 * optimizer_.N]
    speed = new_DV[2 * optimizer_.N:3 * optimizer_.N]
    Heading = s["Heading"] + np.cumsum(heading)
    Speed = s["Speed"] + np.cumsum(speed)
    height = Speed * np.tan(Slope)
    x = Speed * np.sin(Heading)
    y = Speed * np.cos(Heading)

    delta_opt = {
        "heading" : heading,
        "Slope" : Slope,
        "speed" : speed,
        "height" : height,
        "x" : x,
        "y" : y
    }
    
    if ref_GPS is None:
        visuallize(s, e, delta_opt)
        recover_df = recover_visuallize(s, delta_opt, show)
    else:
        visuallize(s, e, delta_opt, ref_GPS)
        recover_df = recover_visuallize(s, delta_opt, ref_GPS, show)
    
    return recover_df
